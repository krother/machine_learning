{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Nemo\n",
    "\n",
    "**Build an image classifier**\n",
    "\n",
    "1.  Chop up the image into slices of 224x224 pixels\n",
    "2.  Predict labels using a pre-trained network (e.g. MobileNet)\n",
    "3.  Collect labels / predictions for all slices\n",
    "4.  Filter out predictions that are below a certain probability threshold\n",
    "5.  Analyze the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's use Keras' image module to load and manipulate images!\n",
    "\n",
    "**Note**, there are many ways to read in images in python; for example:\n",
    "- `matplotlib.pyplot.plt.imread()`\n",
    "- `cv2.imread()`\n",
    "- `tensorflow.keras.preprocessing.image.load_img()`\n",
    "- `PIL.Image.open()`\n",
    " \n",
    "Pick whichever method works for you! The most important thing at the end of the day is that we can work with the image as an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "img = image.load_img('aquarium.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the image to an array, and check out some of the properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array = image.img_to_array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract a single 1x224x224x3 slice of the image\n",
    "- Those are the dimensions of the images from the ImageNet data set (on which many popular models were trained, e.g. VGG, MobileNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fish = img_array[___:___, ___:___, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fish = np.expand_dims(fish, axis=0) #to add the extra \"1\" dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a prediction from the image slice\n",
    "- We're going to use MobileNet since it's small and works decently well out-of-the-box.\n",
    "- There are others you can check out:\n",
    "    - https://www.tensorflow.org/api_docs/python/tf/keras/applications\n",
    "    - **Warning!** Check out the sizes of some of the pre-trained models:\n",
    "        - https://keras.io/api/applications/\n",
    "        - some larger models could crash your Jupyter Notebook if you don't have enough memory.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input, decode_predictions\n",
    "\n",
    "### ------ other models you can try out ------ ###\n",
    "# from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "# from tensorflow.keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MobileNetV2(weights='imagenet', include_top=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "           metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(fish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_predictions(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect multiple slices / \"tiles\" by looping over the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles = []\n",
    "\n",
    "for x in range(0, ___, ___):\n",
    "    \n",
    "    for y in range(0, ___, ___):\n",
    "        \n",
    "        tile = img_array[___, ___, :]\n",
    "        \n",
    "        if tile.shape == (___, ___, ___):\n",
    "            \n",
    "            tiles.append(tile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the pre-trained model to make predictions on the collected image tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles = np.array(tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_predictions(model.predict(tiles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect labels with the highest probabilty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discuss the results of this manual image recognition system.\n",
    "- What are some of the reasons why we still get weird results?\n",
    "- What could we do to improve the model?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
