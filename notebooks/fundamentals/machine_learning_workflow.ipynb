{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Workflow\n",
    "\n",
    "**In this session, we will walk through solving a Machine Learning problem from one end to another.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Define Business Goal\n",
    "\n",
    "**We want to predict the species of a penguin from their body measures.**\n",
    "\n",
    "![](penguin_heads.png)\n",
    "\n",
    "We will assume this goal as given, although in practice, figuring out *what* the task is a lot of work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Get Data\n",
    "getting clean data is also a huge effort. Again, this is not the topic of this session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/penguins_simple.csv', sep=';')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Split Data into Training, Validation and Test sets\n",
    "\n",
    "* training: what we use to explore the data and train the model\n",
    "* validation: what we use to iteratively evaluate and optimize the model\n",
    "* test: what we use **once** to estimate the error rate of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val, test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train, val = train_test_split(train_val, test_size=0.2, random_state=43)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1: Check the number of items in train, val and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Explore Data\n",
    "\n",
    "use **only** the training data for exploration to prevent *data leakage*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of target classes\n",
    "train['Species'].value_counts().plot.barh()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2: Interpret the bar plot. Can we achieve an accuracy better than 33%?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation of numerical features\n",
    "sns.pairplot(train, hue='Species')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3: Interpret the pair plot. \n",
    "* Can we hope to predict anything?\n",
    "* Is there a species that is easier to predict?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Define X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X is a matrix of input features\n",
    "COLUMNS = ['Culmen Length (mm)', 'Culmen Depth (mm)',\n",
    "           'Flipper Length (mm)', 'Body Mass (g)', 'Sex'\n",
    "          ]\n",
    "Xtrain = train[COLUMNS]\n",
    "Xval = val[COLUMNS]\n",
    "\n",
    "# y is a categorical variable --> Classification\n",
    "ytrain = train['Species']\n",
    "yval = val['Species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain.shape, ytrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xval.shape, yval.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the MALE/FEMALE column to 0/1\n",
    "ohc = ColumnTransformer([\n",
    "    ('one-hot', OneHotEncoder(drop='first', handle_unknown='error', sparse=False), ['Sex']),\n",
    "    ('do nothing', 'passthrough', COLUMNS[:-1])\n",
    "])\n",
    "ohc.fit(Xtrain)\n",
    "Xtrans = ohc.transform(Xtrain)\n",
    "Xtrans.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 4: Inspect the data type of `Xtrans`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Train a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = DecisionTreeClassifier(max_depth=2)   # here we set hyperparameters\n",
    "m.fit(Xtrans, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = m.predict(Xtrans)\n",
    "acc_train = accuracy_score(ytrain, ypred)\n",
    "f\"training accuracy {acc_train:4.2f}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 5: The code below does not work. What did we miss?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred_val = m.predict(Xval)\n",
    "acc_val = accuracy_score(yval, ypred_val)\n",
    "f\"validation accuracy {acc_val:4.2f}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now optimize until you are happy with the outcome, or stop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Estimate model error\n",
    "\n",
    "do this *once*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 6: Complete the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest = test[COLUMNS]\n",
    "ytest = test['Species']\n",
    "\n",
    "Xtest_trans = ...\n",
    "ypred_test = ...\n",
    "acc_test = ...\n",
    "f\"validation accuracy {acc_val:4.2f}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Deploy the model\n",
    "here we just save the model to a file to use it elsewhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(m, open('../models/penguin_tree.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls -l penguin*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
